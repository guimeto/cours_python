{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Etape 3 : Data Cleaning </h1>\n",
    "\n",
    "Etape très importante qui vise à analyser chaque colonne du dataset et de les modifier si besoin pour : \n",
    "- Ajuster la colonne à prédire <br>\n",
    "- Corriger le format des colonnes <br>\n",
    "- Supprimer les colonnes avec trop de valeurs manquantes <br>\n",
    "- Corriger des valeurs manquantes ou erronées <br>\n",
    "- Faire du feature modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "data = pd.concat([train,test],sort=True)\n",
    "data.reset_index(inplace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Préparation de la donnée </h1>\n",
    "\n",
    "<b> La valeur à prédire : le prix de la maison </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['SalePrice'].isnull().sum())\n",
    "print(train['SalePrice'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(train['SalePrice'])\n",
    "plt.title('Kurtosis : ' +str(train['SalePrice'].kurtosis())+ ', Skewness :' + str(train['SalePrice'].skew()))\n",
    "plt.show()\n",
    "print(train['SalePrice'].kurtosis())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Les autres colonnes </b> <br><br>\n",
    "Ont-elles le bon format ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['SalePrice'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['1stFlrSF'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data['1stFlrSF'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "echantillonColonnes = []\n",
    "for i in data.columns:\n",
    "    listcolumn = str(list(data[i].head(5)))\n",
    "    echantillonColonnes.append(listcolumn)\n",
    "echantillonColonnes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(data.dtypes[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = {'colonne': list(data.columns), 'type': list(data.dtypes), 'Echantillon':echantillonColonnes}\n",
    "colonnesTypes = pd.DataFrame(data=d)\n",
    "\n",
    "pd.options.display.max_rows = 81\n",
    "colonnesTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Les autres colonnes comportent-elles des valeurs manquantes </b> <br> <br>\n",
    "La régression linéaire n'accèpte pas les valeurs manquantes, nous devons donc néttoyé le Data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' : data_na})\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas de règle universelle mais si une colonne à plus de 50% de données manquantes il faut la retirer du dataset. Mais si on regarde la définition de PoolQC, MiscFeature, Alley, Fence et FireplaceQu 'Na' veut dire 'Pas de piscine', 'Pas de caractéristique particulière', 'Pas d'allée etc'...c'est donc bien une information ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['PoolQC','MiscFeature','Alley','Fence','FireplaceQu']].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['PoolQC','MiscFeature','Alley','Fence','FireplaceQu']] = data[['PoolQC','MiscFeature','Alley','Fence','FireplaceQu']].fillna(\"None\")\n",
    "data[['PoolQC','MiscFeature','Alley','Fence','FireplaceQu']].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LotFrontage = ligne de facade, c'est à dire la longueur du terrain commun à la rue.<br>\n",
    "Première méthode : remplacer une variable numérique manquante par sa médiane (adaptée au data set avec des valeurs abérentes) ou sa moyenne (adapté aux data set sans valeur abérente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(data['LotFrontage'][data['LotFrontage'].notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['LotFrontage'][data['LotFrontage']>150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LotFrontage'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LotFrontage'] = data['LotFrontage'].fillna(data['LotFrontage'].median())\n",
    "data['LotFrontage'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les valeurs manquantes relatives aux garages indiquent en réalité l'absence de garage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond','GarageYrBlt', 'GarageArea', 'GarageCars']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les valeurs qualitatives nous allons placer 'None' pour toute information manquante. <br>\n",
    "Pour les valeurs quantitatives nous allons placer '0' pour toute information manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']] = data[['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']].fillna(\"None\")\n",
    "data[['GarageYrBlt', 'GarageArea', 'GarageCars']] = data[['GarageYrBlt', 'GarageArea', 'GarageCars']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On continue ce travail sur toutes les variables suivantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']] = data[['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']].fillna(0)\n",
    "data[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']] = data[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].fillna(\"None\")\n",
    "data[\"MasVnrType\"] = data[\"MasVnrType\"].fillna(\"None\")\n",
    "data[\"MasVnrArea\"] = data[\"MasVnrArea\"].fillna(0)\n",
    "data['MSZoning'] = data['MSZoning'].fillna(data['MSZoning'].mode()[0])\n",
    "data = data.drop(['Utilities'], axis=1)\n",
    "data[\"Functional\"] = data[\"Functional\"].fillna(\"Typ\")\n",
    "data['Electrical'] = data['Electrical'].fillna(data['Electrical'].mode()[0])\n",
    "data['KitchenQual'] = data['KitchenQual'].fillna(data['KitchenQual'].mode()[0])\n",
    "data['Exterior1st'] = data['Exterior1st'].fillna(data['Exterior1st'].mode()[0])\n",
    "data['Exterior2nd'] = data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])\n",
    "data['SaleType'] = data['SaleType'].fillna(data['SaleType'].mode()[0])\n",
    "data['MSSubClass'] = data['MSSubClass'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et on vérifie finalement si certaines valeurs sont encore manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aller plus loin :https://towardsdatascience.com/handling-missing-values-in-machine-learning-part-1-dda69d4f88ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Est-ce que l'information contenue dans une des colonnes ne peut pas être correlée au prix de la maison ? </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Id'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['Id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Est-ce que certaines informations numériques sont réellement numériques ? <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['MSSubClass','OverallCond','YrSold','MoSold']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSSubClass: The building class <br>\n",
    "- OverallCond: Overall condition rating <br>\n",
    "- MoSold: Month Sold <br>\n",
    "- YrSold: Year Sold <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['MSSubClass','OverallCond','YrSold','MoSold']] = data[['MSSubClass','OverallCond','YrSold','MoSold']].astype('object')\n",
    "data[['MSSubClass','OverallCond','YrSold','MoSold']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-ce qu'il n'est pas possible ici de faire du feature modeling ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['YearBuilt','YearRemodAdd']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().year\n",
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['years since last remod'] = current_date - data['YearRemodAdd']\n",
    "data.drop(['YearBuilt','YearRemodAdd'], axis=1, inplace = True)\n",
    "data['years since last remod'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Préparer ses datasets de test et d'entrainement<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = data.loc[:1459,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "dataset['SalePrice'] = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.drop(['index'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_indices = random.sample(range(0, len(dataset)),k=len(dataset))\n",
    "dataset.iloc[random_indices].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "random_indices = random.sample(range(0, len(dataset)),k=len(dataset))\n",
    "datasetR = dataset.iloc[random_indices]\n",
    "datasetR.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetR.reset_index(inplace=True)\n",
    "datasetR.drop(['index'],axis=1, inplace=True)\n",
    "datasetR.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = round(len(datasetR)*0.8)\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsTrain = datasetR.iloc[0:cut,:]\n",
    "dsTest = datasetR.iloc[cut:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Créer son premier modèle de prédiction avec une regression univariée</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = datasetR['GrLivArea'], y = datasetR['SalePrice'])\n",
    "plt.ylabel('SalePrice')\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = linear_model.LinearRegression() #quel type de modèle je souhaite utiliser ?\n",
    "\n",
    "lr.fit(dsTrain[['GrLivArea']],dsTrain['SalePrice']) # entrainement du modèle\n",
    "\n",
    "prediction = lr.predict(dsTest[['GrLivArea']]) # réaliser la prédiction\n",
    "prediction[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(prediction,dsTest['SalePrice'])**(1/2) # calculer l'erreur\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegression(datasetR,fit,toPredict):\n",
    "    \n",
    "    cut = round(len(datasetR)*0.8)\n",
    "    dsTrain = datasetR.iloc[0:cut,:].reset_index()\n",
    "    dsTest = datasetR.iloc[cut:,:]\n",
    "    \n",
    "    lr = linear_model.LinearRegression() \n",
    "    lr.fit(dsTrain[fit],dsTrain[toPredict])\n",
    "    prediction = lr.predict(dsTest[fit])\n",
    "    rmse = mean_squared_error(prediction,dsTest[toPredict])**(1/2)\n",
    "    return rmse\n",
    "\n",
    "linearRegression(datasetR,['GrLivArea'],'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Standardisation des valeurs </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetR.select_dtypes(include=['int64','float64']).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullListNumbersAndPrice = list(datasetR.select_dtypes(include=['int64','float64']).columns)\n",
    "#print(fullListNumbersAndPrice)\n",
    "\n",
    "fullListNumbers = fullListNumbersAndPrice[:-1]\n",
    "print(fullListNumbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "dfStand = scaler.fit_transform(datasetR[fullListNumbers])\n",
    "dfStand = pd.DataFrame(dfStand, columns=fullListNumbers)\n",
    "dfStand.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegression(datasetR,fit,toPredict):\n",
    "    fullListNumbers = list(datasetR.select_dtypes(include=['int64','float64']).columns)\n",
    "    fullListNumbers = fullListNumbers[:-1]\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    dfStand = scaler.fit_transform(datasetR[fullListNumbers])\n",
    "    dfStand = pd.DataFrame(dfStand, columns=fullListNumbers)\n",
    "    datasetR[fullListNumbers] = dfStand\n",
    "    \n",
    "    cut = round(len(datasetR)*0.8)\n",
    "    dsTrain = datasetR.iloc[0:cut,:].reset_index()\n",
    "    dsTest = datasetR.iloc[cut:,:]\n",
    "    \n",
    "    lr = linear_model.LinearRegression() \n",
    "    lr.fit(dsTrain[fit],dsTrain[toPredict])\n",
    "    prediction = lr.predict(dsTest[fit])\n",
    "    rmse = mean_squared_error(prediction,dsTest[toPredict])**(1/2)\n",
    "    return rmse\n",
    "\n",
    "linearRegression(datasetR,['GrLivArea'],'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Regression linéaire avec plusieurs colonnes d'entrainement </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetR['GarageCars'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = ['GrLivArea','GarageCars']\n",
    "linearRegression(datasetR,fit,'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youhou ! on a plus qu'à ajouter toutes les colonnes ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(fullListNumbers)):\n",
    "    fit = fullListNumbers[0:i+1]\n",
    "    result = linearRegression(datasetR,fit,'SalePrice')\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(min(results))\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(y=results, x=list(np.arange(0,len(fullListNumbers))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Faire le tri parmi les features numériques </b> <br>\n",
    "<p> Ecarter les colonnes avec une corrélation faible avec le prix <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetR[fullListNumbersAndPrice].corr().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = datasetR[fullListNumbersAndPrice].corr()\n",
    "corrSalesprice = df_corr.sort_values('SalePrice',ascending=False)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=corrSalesprice['SalePrice'], y=corrSalesprice.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = abs(datasetR[fullListNumbersAndPrice].corr())\n",
    "corrSalesprice = df_corr.sort_values('SalePrice',ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=corrSalesprice['SalePrice'], y=corrSalesprice.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.00-0.19: very weak <br>\n",
    "0.20-0.39: weak <br>\n",
    "0.40-0.59: moderate <br>\n",
    "0.60-0.79: strong <br>\n",
    "0.80-1.00: very strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less20Percent = list(corrSalesprice[corrSalesprice['SalePrice'] > 0.2].index)\n",
    "less20Percent.remove('SalePrice')\n",
    "print(less20Percent)\n",
    "\n",
    "less40Percent = list(corrSalesprice[corrSalesprice['SalePrice'] > 0.4].index)\n",
    "less40Percent.remove('SalePrice')\n",
    "print(less40Percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linearRegression(datasetR,fullListNumbers,'SalePrice'))\n",
    "print(linearRegression(datasetR,less20Percent,'SalePrice')) #Winner ! \n",
    "print(linearRegression(datasetR,less40Percent,'SalePrice'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer les colonnes trop similaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less20Percent.append('SalePrice')\n",
    "fullListNumbers = less20Percent\n",
    "df_corr = abs(datasetR[fullListNumbers].corr())   \n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(df_corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que certaines caractéristiques semblent liés : <br>\n",
    "\n",
    "- Total bsmt SF (Total square feet of basement area) et 1st Flr SF (First Floor square feet)\n",
    "- Gr Liv Area (Above grade (ground) living area square feet) et TotRms AbvGrd (Total rooms above grade (does not include bathrooms)\n",
    "- Garage cars (Size of garage in car capacity) et garage Area (Garage Area)\n",
    "\n",
    "Afin d'éviter d'avoir des informations qui se doublonne et donc ne faire qu'ajouter du bruit l'une à l'autre, nous n'allons conservé que celles ayant le plus fort taux de correlation de chaque couple avec le prix :\n",
    "\n",
    "- Total bsmt SF\n",
    "- Gr Liv Area\n",
    "- GarageArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullListNumbers.remove('1stFlrSF')\n",
    "fullListNumbers.remove('TotRmsAbvGrd')\n",
    "fullListNumbers.remove('GarageCars')\n",
    "#'2ndFlrSF'\n",
    "print(fullListNumbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullListNumbers.remove('SalePrice')\n",
    "linearRegression(datasetR,fullListNumbers,'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Intégration des valeurs catégoricielles </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcatColumns = list(datasetR.select_dtypes(include=['object']).columns)\n",
    "print(allcatColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasetR.groupby(datasetR['Alley']).size().sort_values(ascending=False)\n",
    "sns.barplot(x=list(test.index), y=list(test.iloc[0:]))\n",
    "print('Alley' + ' - nombre de catégories : ' + str(len(test)) + ' - Pourcentage de la valeur 1 : ' + str(test[0]/len(datasetR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous trions mainteant parmis les données catégoricielles. Il faut d'abord retirer celles ne variant pas assez ou ayant trop de valeurs différentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in allcatColumns:\n",
    "    test = datasetR.groupby(datasetR[i]).size().sort_values(ascending=False)\n",
    "    print(i + ' - nombre de catégories : ' + str(len(test)) + ' - Pourcentage de la valeur 1 : '+ str(test.iloc[0]/len(datasetR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parce qu'une même valeur est rencontrée dans plus de 80% des cas, ou un nombre de catégories trop importantes est constatée nous supprimons ces élements : Alley,BldgType,BsmtCond,BsmtFinType2,CentralAir,Condition1,Condition2,Electrical,ExterCond,Exterior1st,Exterior2nd,Fence,\n",
    "Functional,GarageCond,GarageQual,Heating,LandContour,LandSlope,MSSubClass,MiscFeature,MoSold,Neighborhood,PavedDrive,PoolQC,\n",
    "RoofMatl,SaleCondition,SaleType,Street  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toDelete = ['Alley','BldgType','BsmtCond','BsmtFinType2','CentralAir','Condition1','Condition2','Electrical','ExterCond','Exterior1st','Exterior2nd','Fence','Functional','GarageCond','GarageQual','Heating','LandContour','LandSlope','MSSubClass','MiscFeature','MoSold','Neighborhood','PavedDrive','PoolQC','RoofMatl','SaleCondition','SaleType','Street']  \n",
    "for i in toDelete:\n",
    "    allcatColumns.remove(i)\n",
    "\n",
    "print(allcatColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linearRegression(datasetR,fit,toPredict):\n",
    "    fullListNumbers = list(datasetR.select_dtypes(include=['int64','float64']).columns)\n",
    "    fullListNumbers = fullListNumbers[:-1]\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    dfStand = scaler.fit_transform(datasetR[fullListNumbers])\n",
    "    dfStand = pd.DataFrame(dfStand, columns=fullListNumbers)\n",
    "    datasetR[fullListNumbers] = dfStand\n",
    "    \n",
    "    allcatColumns = list(datasetR[fit].select_dtypes(include=['object']).columns)\n",
    "    dummy_cols = pd.DataFrame()\n",
    "    for col in allcatColumns:\n",
    "        col_dummies = pd.get_dummies(datasetR[col],prefix=str(col))\n",
    "        datasetR = pd.concat([datasetR, col_dummies], axis=1)\n",
    "        del datasetR[col]\n",
    "        fit = fit + list(col_dummies.columns)\n",
    "        fit.remove(col)\n",
    "\n",
    "    cut = round(len(datasetR)*0.8)\n",
    "    dsTrain = datasetR.iloc[0:cut,:]\n",
    "    dsTest = datasetR.iloc[cut:,:]\n",
    "    \n",
    "    lr = linear_model.LinearRegression() \n",
    "    lr.fit(dsTrain[fit],dsTrain[toPredict])\n",
    "    prediction = lr.predict(dsTest[fit])\n",
    "    rmse = mean_squared_error(prediction,dsTest[toPredict])**(1/2)\n",
    "    return rmse\n",
    "\n",
    "fullcolumnslist =  fullListNumbers + allcatColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullcolumnslist =  fullListNumbers + allcatColumns\n",
    "\n",
    "result = linearRegression(datasetR,['OverallQual'],'SalePrice')\n",
    "\n",
    "newcolumns = ['OverallQual']\n",
    "for i in range(len(fullcolumnslist)):\n",
    "    fit = fullcolumnslist[0:i+1]\n",
    "    test = linearRegression(datasetR,fit,'SalePrice')\n",
    "    if test < result:\n",
    "        newcolumns.append(fullcolumnslist[i])\n",
    "        result = test\n",
    "        \n",
    "print(newcolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearRegression(datasetR,newcolumns,'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vous ! Adaptez la fonction pour tester votre modèle sur le jeu de données d'entrainement du concours ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetR[fullcolumnslist]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
